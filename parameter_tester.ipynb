{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37764bitaudiosegmentationpipenv7bfd96a09dae4c54b4e92e12f8b8a3ad",
   "display_name": "Python 3.7.7 64-bit ('audio_segmentation': pipenv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Use this script to test and find the best silence lens and threshold\n",
    "# Splices fragment of audio file\n",
    "#TODO https://stackoverflow.com/questions/59102171/getting-timestamps-from-audio-using-python\n",
    "#TODO add directory\n",
    "\n",
    "from pydub import AudioSegment\n",
    "from pydub.utils import make_chunks\n",
    "\n",
    "\n",
    "audio_path = input(\"Input audio path\") #path refers to the file\n",
    "loaded_audio = AudioSegment.from_file(audio_path, format=\"m4a\")\n",
    "\n",
    "#Parameters\n",
    "predefined_ms = 120 * 1000 # pydub calculates in millisec\n",
    "\n",
    "#Determine whether to splice first or last seconds of audio\n",
    "spliced_test_audio = loaded_audio[:predefined_ms] \n",
    "#spliced_test_audio = loaded_audio[-predefined_ms:] \n",
    "\n",
    "#Export spliced sample audio\n",
    "spliced_test_audio.export(\"TEEEEST.wav\", format=\"wav\")# Use this script to test and find the best \n",
    "print(\"Audio successfully spliced\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Use this to adjust parameters. Check if the start and stop times correspond with wave plot.\n",
    "\n",
    "from pydub import AudioSegment\n",
    "from pydub.silence import detect_nonsilent\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "#Convert test wav to audio_segment\n",
    "audio_segment = AudioSegment.from_wav(\"TEEEEST.wav\")\n",
    "\n",
    "#Convert seconds into timestamp\n",
    "def convert(seconds): \n",
    "    seconds = seconds % (24 * 3600) \n",
    "    hour = seconds // 3600\n",
    "    seconds %= 3600\n",
    "    minutes = seconds // 60\n",
    "    seconds %= 60\n",
    "      \n",
    "    return \"%d:%02d:%02d\" % (hour, minutes, seconds) \n",
    "\n",
    "#adjust target amplitude\n",
    "def match_target_amplitude(sound, target_dBFS):\n",
    "    change_in_dBFS = target_dBFS - sound.dBFS\n",
    "    return sound.apply_gain(change_in_dBFS)\n",
    "\n",
    "#normalize audio_segment to -20dBFS \n",
    "normalized_sound = match_target_amplitude(audio_segment, -20.0)\n",
    "audio_length = len(normalized_sound)/1000 #required for plotting wave graph\n",
    "print(\"length of audio_segment={} seconds\".format(len(normalized_sound)/1000))\n",
    "\n",
    "#Print detected non-silent chunks, which in our case would be spoken words.\n",
    "#the lower the silence threshold (higher negative number), the less senstive it is\n",
    "nonsilent_data = detect_nonsilent(normalized_sound, min_silence_len=4000, silence_thresh=-32, seek_step=1)\n",
    "\n",
    "#convert ms to seconds\n",
    "print(\"start,Stop\")\n",
    "for chunks in nonsilent_data:\n",
    "    print([convert(chunk/1000) for chunk in chunks])\n",
    " \n",
    "\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa.display\n",
    "\n",
    "#Plots the sample test audio\n",
    "test_dir = \"TEEEEST.wav\"\n",
    "audio_data, sampling_rate = librosa.load(test_dir)\n",
    "plt.figure(figsize=(14, 5))\n",
    "librosa.display.waveplot(audio_data, sr=sampling_rate)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}